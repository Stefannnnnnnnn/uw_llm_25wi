{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iiUXLUQq8XR"
      },
      "source": [
        "## Coding Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ranking Documents Report (10 Points)\n",
        "\n",
        "Students must analyze which encoding methods performed best for document ranking.\n",
        "\n",
        "What to include in your report:\n",
        "    \n",
        "#Comparison of Encoding Methods\n",
        "\n",
        "Compare GloVe embeddings vs. Sentence Transformer embeddings.\n",
        "Which method ranked documents better?\n",
        "Did the top-ranked documents make sense?\n",
        "How does cosine similarity behave with different embeddings?\n",
        "\n",
        "#Observations on Cosine Similarity & Ranking\n",
        "\n",
        "Did the ranking appear meaningful?\n",
        "Were there cases where documents that should be highly ranked were not?\n",
        "What are possible explanations for incorrect rankings?\n",
        "\n",
        "#Possible Improvements\n",
        "\n",
        "What can be done to improve document ranking?\n",
        "Would a different distance metric (e.g., Euclidean, Manhattan) help?\n",
        "Would preprocessing the queries or documents (e.g., removing stopwords) improve ranking?\n",
        "\n",
        "\n",
        "Fine-Tuning Report (15 Points)\n",
        "\n",
        "After fine-tuning, students must compare different training approaches and reflect on their findings.\n",
        "\n",
        "What to include in your report:\n",
        "    \n",
        "#Comparison of Different Training Strategies\n",
        "\n",
        "[anchor, positive] vs [anchor, positive, negative].\n",
        "Which approach seemed to improve ranking?\n",
        "How did the model behave differently?\n",
        "\n",
        "#Impact on MAP Score\n",
        "\n",
        "Did fine-tuning improve or hurt the Mean Average Precision (MAP) score?\n",
        "If MAP decreased, why might that be?\n",
        "Is fine-tuning always necessary for retrieval models?\n",
        "\n",
        "#Observations on Training Loss & Learning Rate\n",
        "\n",
        "Did the loss converge?\n",
        "Was the learning rate too high or too low?\n",
        "How did freezing/unfreezing layers impact training?\n",
        "\n",
        "#Future Improvements\n",
        "\n",
        "Would training with more negatives help?\n",
        "Would changing the loss function (e.g., using Softmax Loss) improve performance?\n",
        "Could increasing the number of epochs lead to a better model?\n"
      ],
      "metadata": {
        "id": "OdD7GR_kPMPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets sentence_transformers"
      ],
      "metadata": {
        "id": "G7GnxQSgPGnM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "989ecf76-45ff-4919-e2c0-90cf1dda8101"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.48.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sympy import false\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "r49U3ocTHej8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def collate_fn(batch):\n",
        "#         \"\"\"\n",
        "#         Custom collate function to process InputExample objects into the format that\n",
        "#         the model can accept.\n",
        "#         \"\"\"\n",
        "#         # Extract texts from InputExample objects\n",
        "#         texts = [example.texts for example in batch]\n",
        "\n",
        "#         # The model will accept texts as input (two texts for each pair)\n",
        "#         return texts\n",
        "\n",
        "class TextSimilarityModel:\n",
        "    def __init__(self, corpus_name, rel_name, model_name='all-MiniLM-L6-v2', top_k=10):\n",
        "        \"\"\"\n",
        "        Initialize the model with datasets and pre-trained sentence transformer.\n",
        "        \"\"\"\n",
        "        self.model = SentenceTransformer(\"/content/finetuned_senBERT_train_v2_21ep_lr5e-4\")\n",
        "        # \"/content/finetuned_senBERT_train_v2\" model_name\n",
        "        self.corpus_name = corpus_name\n",
        "        self.rel_name = rel_name\n",
        "        self.top_k = top_k\n",
        "\n",
        "        ### Add Init\n",
        "        self.query_id_to_ranked_doc_ids = {}\n",
        "        self.glove_embedding_dict = {}\n",
        "        self.add_negative = False\n",
        "\n",
        "        ###\n",
        "        self.load_data()\n",
        "\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Load and filter datasets based on test queries and documents.\n",
        "        \"\"\"\n",
        "        # Load query and document datasets\n",
        "        dataset_queries = load_dataset(self.corpus_name, \"queries\")\n",
        "        dataset_docs = load_dataset(self.corpus_name, \"corpus\")\n",
        "\n",
        "        # Extract queries and documents\n",
        "        self.queries = dataset_queries[\"queries\"][\"text\"]\n",
        "        self.query_ids = dataset_queries[\"queries\"][\"_id\"]\n",
        "        self.documents = dataset_docs[\"corpus\"][\"text\"]\n",
        "        self.document_ids = dataset_docs[\"corpus\"][\"_id\"]\n",
        "\n",
        "        self.kaggle_test_queries = pd.read_csv(\"test_query.csv\")[\"Query\"].tolist()\n",
        "        self.ori_kaggle_test_document_ids = pd.read_csv(\"test_documents.csv\")[\"Doc\"].tolist()\n",
        "        self.kaggle_test_documents = [doc for did, doc in zip(self.document_ids, self.documents) if did in self.ori_kaggle_test_document_ids]\n",
        "        self.kaggle_test_document_ids = [did for did, doc in zip(self.document_ids, self.documents) if did in self.ori_kaggle_test_document_ids]\n",
        "\n",
        "        # Filter queries and documents and build relevant queries and documents mapping based on test set\n",
        "        test_qrels = load_dataset(self.rel_name)[\"test\"]\n",
        "        self.filtered_test_query_ids = set(test_qrels[\"query-id\"])\n",
        "        self.filtered_test_doc_ids = set(test_qrels[\"corpus-id\"])\n",
        "\n",
        "        self.test_queries = [q for qid, q in zip(self.query_ids, self.queries) if qid in self.filtered_test_query_ids]\n",
        "        self.test_query_ids = [qid for qid in self.query_ids if qid in self.filtered_test_query_ids]\n",
        "        self.test_documents = [doc for did, doc in zip(self.document_ids, self.documents) if did in self.filtered_test_doc_ids]\n",
        "        self.test_document_ids = [did for did in self.document_ids if did in self.filtered_test_doc_ids]\n",
        "\n",
        "        self.test_query_id_to_relevant_doc_ids = {qid: [] for qid in self.test_query_ids}\n",
        "        for qid, doc_id in zip(test_qrels[\"query-id\"], test_qrels[\"corpus-id\"]):\n",
        "            if qid in self.test_query_id_to_relevant_doc_ids:\n",
        "                self.test_query_id_to_relevant_doc_ids[qid].append(doc_id)\n",
        "\n",
        "        ## Code Below this is used for creating the training set\n",
        "        # Build query and document id to text mapping\n",
        "        self.query_id_to_text = {query_id:query for query_id, query in zip(self.query_ids, self.queries)}\n",
        "        self.document_id_to_text = {document_id:document for document_id, document in zip(self.document_ids, self.documents)}\n",
        "\n",
        "        # Build relevant queries and documents mapping based on train set\n",
        "        train_qrels = load_dataset(self.rel_name)[\"train\"]\n",
        "        self.train_query_id_to_relevant_doc_ids = {qid: [] for qid in train_qrels[\"query-id\"]}\n",
        "\n",
        "        for qid, doc_id in zip(train_qrels[\"query-id\"], train_qrels[\"corpus-id\"]):\n",
        "            if qid in self.train_query_id_to_relevant_doc_ids:\n",
        "                # Append the document ID to the relevant doc mapping\n",
        "                self.train_query_id_to_relevant_doc_ids[qid].append(doc_id)\n",
        "\n",
        "        # Filter queries and documents and build relevant queries and documents mapping based on validation set\n",
        "        #TODO Put your code here. Done by Tianyi Li on 02/06/2025\n",
        "         ###########################################################################\n",
        "        # Build relevant queries and documents mapping based on validation set\n",
        "        validate_qrels = load_dataset(self.rel_name)[\"validation\"]\n",
        "        self.validate_query_id_to_relevant_doc_ids = {qid: [] for qid in validate_qrels[\"query-id\"]}\n",
        "\n",
        "        for qid, doc_id in zip(validate_qrels[\"query-id\"], validate_qrels[\"corpus-id\"]):\n",
        "            if qid in self.validate_query_id_to_relevant_doc_ids:\n",
        "                # Append the document ID to the relevant doc mapping\n",
        "                self.validate_query_id_to_relevant_doc_ids[qid].append(doc_id)\n",
        "        ###########################################################################\n",
        "\n",
        "    def kaggle_rank_documents(self, encoding_method: str = 'sentence_transformer') -> None:\n",
        "        query_embeddings = self.model.encode(self.kaggle_test_queries)\n",
        "        document_embeddings = self.model.encode(self.kaggle_test_documents)\n",
        "\n",
        "        self.query_to_ranked_doc_ids = {}\n",
        "        query_embeddings = np.array(query_embeddings)\n",
        "        document_embeddings = np.array(document_embeddings)\n",
        "        cosine_similarities = cosine_similarity(query_embeddings,document_embeddings)\n",
        "        for query, similarity_scores in zip(self.kaggle_test_queries, cosine_similarities):\n",
        "            sorted_indices = np.argsort(similarity_scores)[::-1][:self.top_k]  # Sort in descending order\n",
        "            ranked_doc_ids = [self.kaggle_test_document_ids[idx] for idx in sorted_indices]  # Map indices to document IDs\n",
        "            self.query_to_ranked_doc_ids[query] = ranked_doc_ids\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            \"Query\": self.query_to_ranked_doc_ids.keys(),\n",
        "            \"Doc_ID\": [\" \".join(docs) for docs in self.query_to_ranked_doc_ids.values()]\n",
        "        })\n",
        "        df.to_csv(\"output.csv\", index=False, sep=\",\")\n",
        "\n",
        "    #Task 2: Calculate Cosine Similarity and Rank Documents (20 Pts)\n",
        "    def rank_documents(self, encoding_method: str = 'sentence_transformer') -> None:\n",
        "        \"\"\"\n",
        "         # Inputs:\n",
        "            - encoding_method (str): The method used for encoding queries/documents.\n",
        "                             Options: ['glove', 'sentence_transformer'].\n",
        "\n",
        "        # Output:\n",
        "            - None (updates self.query_id_to_ranked_doc_ids with ranked document IDs).\n",
        "\n",
        "        (1) Compute cosine similarity between each document and the query\n",
        "        (2) Rank documents for each query and save the results in a dictionary \"query_id_to_ranked_doc_ids\"\n",
        "            This will be used in \"mean_average_precision\"\n",
        "            Example format {2: [125, 673], 35: [900, 822]}\n",
        "        \"\"\"\n",
        "        if encoding_method == 'glove':\n",
        "            query_embeddings = self.encode_with_glove(\"glove.6B.50d.txt\", self.queries)\n",
        "            document_embeddings = self.encode_with_glove(\"glove.6B.50d.txt\", self.documents)\n",
        "        elif encoding_method == 'sentence_transformer':\n",
        "            query_embeddings = self.model.encode(self.queries)\n",
        "            document_embeddings = self.model.encode(self.documents)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid encoding method. Choose 'glove' or 'sentence_transformer'.\")\n",
        "\n",
        "        #TODO Put your code here. Done by Tianyi Li on 02/05/2025\n",
        "        ###########################################################################\n",
        "         # define a dictionary to store the ranked documents for each query\n",
        "\n",
        "        query_embeddings = np.array(query_embeddings)\n",
        "        document_embeddings = np.array(document_embeddings)\n",
        "        cosine_similarities = cosine_similarity(query_embeddings,document_embeddings)\n",
        "        for query_id, similarity_scores in zip(self.query_ids, cosine_similarities):\n",
        "            sorted_indices = np.argsort(similarity_scores)[::-1][:self.top_k]  # Sort in descending order\n",
        "            ranked_doc_ids = [self.document_ids[idx] for idx in sorted_indices]  # Map indices to document IDs\n",
        "            self.query_id_to_ranked_doc_ids[query_id] = ranked_doc_ids\n",
        "        ###########################################################################\n",
        "\n",
        "    @staticmethod\n",
        "    def average_precision(relevant_docs: list[str], candidate_docs: list[str]) -> float:\n",
        "        \"\"\"\n",
        "        # Inputs:\n",
        "            - relevant_docs (list[str]): A list of document IDs that are relevant to the query.\n",
        "            - candidate_docs (list[str]): A list of document IDs ranked by the model.\n",
        "\n",
        "        # Output:\n",
        "            - float: The average precision score\n",
        "\n",
        "        Compute average precision for a single query.\n",
        "        \"\"\"\n",
        "        y_true = [1 if doc_id in relevant_docs else 0 for doc_id in candidate_docs]\n",
        "        precisions = [np.mean(y_true[:k+1]) for k in range(len(y_true)) if y_true[k]]\n",
        "        return np.mean(precisions) if precisions else 0\n",
        "\n",
        "    #Task 3: Calculate Evaluate System Performance (10 Pts)\n",
        "\n",
        "    def mean_average_precision(self) -> float:\n",
        "        \"\"\"\n",
        "        # Inputs:\n",
        "            - None (uses ranked documents stored in self.query_id_to_ranked_doc_ids).\n",
        "\n",
        "        # Output:\n",
        "            - float: The MAP score, computed as the mean of all average precision scores.\n",
        "\n",
        "        (1) Compute mean average precision for all queries using the \"average_precision\" function.\n",
        "        (2) Compute the mean of all average precision scores\n",
        "        Return the mean average precision score\n",
        "\n",
        "        reference: https://www.evidentlyai.com/ranking-metrics/mean-average-precision-map\n",
        "        https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2\n",
        "        \"\"\"\n",
        "         #TODO Put your code here. Done by DanieL Chen on 02/06/2025\n",
        "        ###########################################################################\n",
        "        average_precisions = [] # Create an empty list average_precisions to store the AP of each query\n",
        "\n",
        "        for qid in self.test_query_ids:\n",
        "            relevant_docs = self.test_query_id_to_relevant_doc_ids[qid]\n",
        "            ranked_docs = self.query_id_to_ranked_doc_ids[qid]\n",
        "            average_precisions.append(self.average_precision(relevant_docs, ranked_docs))\n",
        "\n",
        "        return np.mean(average_precisions) if average_precisions else 0.0\n",
        "\n",
        "        ###########################################################################\n",
        "\n",
        "    #Task 4: Ranking the Top 10 Documents based on Similarity Scores (10 Pts)\n",
        "\n",
        "    def show_ranking_documents(self, example_query: str) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        # Inputs:\n",
        "            - example_query (str): A query string for which top-ranked documents should be displayed.\n",
        "\n",
        "        # Output:\n",
        "            - None (prints the ranked documents along with similarity scores).\n",
        "\n",
        "        (1) rank documents with given query with cosine similarity scores\n",
        "        (2) prints the top 10 results along with its similarity score.\n",
        "\n",
        "        \"\"\"\n",
        "        #TODO Put your code here. Done by DanieL Chen on 02/06/2025\n",
        "        # query_embedding = self.model.encode(example_query)\n",
        "        query_embedding = self.model.encode([example_query])[0] # encode() requires a List format\n",
        "        document_embeddings = self.model.encode(self.documents)\n",
        "        ###########################################################################\n",
        "        cosine_similarities = cosine_similarity([query_embedding], document_embeddings)[0]\n",
        "        sorted_indices = np.argsort(cosine_similarities)[::-1][:10]\n",
        "        ranked_docs = [(self.documents[i], cosine_similarities[i]) for i in sorted_indices]\n",
        "\n",
        "        print(f\"Top 10 documents for query: {example_query}\\n\")\n",
        "\n",
        "        for i, (doc, score) in enumerate(ranked_docs, 1):\n",
        "            print(f\"{i}. Score: {score:.4f}, Document: {doc}\")\n",
        "\n",
        "\n",
        "        ###########################################################################\n",
        "\n",
        "    #Task 5:Fine tune the sentence transformer model (25 Pts)\n",
        "    # Students are not graded on achieving a high MAP score.\n",
        "    # The key is to show understanding, experimentation, and thoughtful analysis.\n",
        "\n",
        "    def fine_tune_model(self, batch_size: int = 64, num_epochs: int = 3, save_model_path: str = \"finetuned_senBERT\", lr: float = 5e-4) -> None:\n",
        "        \"\"\"\n",
        "        Fine-tunes the model using MultipleNegativesRankingLoss.\n",
        "        \"\"\"\n",
        "        # self.add_negative = True\n",
        "        train_examples = self.prepare_training_examples()\n",
        "\n",
        "        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "        # Use MultipleNegativesRankingLoss\n",
        "        train_loss = losses.MultipleNegativesRankingLoss(self.model)\n",
        "\n",
        "        # Freeze all model layers except the final layers\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if \"encoder.layer.5\" in name or \"pooler\" in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Training Loop with Validation\n",
        "        self.model.train()\n",
        "        best_val_loss = float(\"inf\")\n",
        "        patience_counter = 0\n",
        "\n",
        "        # for epoch in range(num_epochs):\n",
        "        self.model.fit(\n",
        "              train_objectives=[(train_dataloader, train_loss)],\n",
        "              epochs=num_epochs,  # Train for 1 epoch each time\n",
        "              # warmup_steps=int(0.1 * len(train_dataloader)),\n",
        "              optimizer_params={'lr': lr},\n",
        "              show_progress_bar=True\n",
        "        )\n",
        "\n",
        "            # # Validation and dynamic early stopping\n",
        "            # val_loss = self.evaluate_validation_loss()  # Implement this function based on your validation data\n",
        "            # print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}\")\n",
        "\n",
        "            # if val_loss < best_val_loss:\n",
        "            #     best_val_loss = val_loss\n",
        "            #     patience_counter = 0\n",
        "            #     self.model.save(save_model_path)  # Save the best model\n",
        "            # else:\n",
        "            #     patience_counter += 1\n",
        "\n",
        "            # if patience_counter > 2:  # Stop training if validation loss doesn't improve for 3 consecutive epochs\n",
        "            #     print(\"Early stopping due to no improvement in validation loss.\")\n",
        "            #     break\n",
        "        self.model.save(save_model_path)\n",
        "\n",
        "    def prepare_training_examples(self) -> list[InputExample]:\n",
        "        \"\"\"\n",
        "        Prepares training examples from the training data.\n",
        "        Adds hard negatives if specified.\n",
        "        \"\"\"\n",
        "        train_examples = []\n",
        "\n",
        "        # Compute sentence embeddings for all documents at once to avoid recomputation\n",
        "        document_embeddings = {doc_id: self.model.encode(text) for doc_id, text in self.document_id_to_text.items()}\n",
        "        for qid, doc_ids in self.train_query_id_to_relevant_doc_ids.items():\n",
        "            anchor = self.query_id_to_text[qid]\n",
        "            anchor_embedding = self.model.encode(anchor)  # Encode the query once\n",
        "\n",
        "            # Get all negative candidates for the current query\n",
        "            negative_candidates = list(set(self.document_ids) - set(doc_ids))\n",
        "\n",
        "            for doc_id in doc_ids:\n",
        "                positive = self.document_id_to_text[doc_id]\n",
        "                positive_embedding = document_embeddings[doc_id]  # Precomputed embedding of positive sample\n",
        "\n",
        "                if self.add_negative:\n",
        "                    # Hard negative mining: select a negative document that is similar but not relevant\n",
        "                    hard_negative = self.select_hard_negative(anchor_embedding, negative_candidates, document_embeddings)\n",
        "                    train_examples.append(InputExample(texts=[anchor, positive, hard_negative]))\n",
        "                else:\n",
        "                    train_examples.append(InputExample(texts=[anchor, positive]))\n",
        "\n",
        "        return train_examples\n",
        "\n",
        "    def select_hard_negative(self, anchor_embedding, negative_candidates, document_embeddings):\n",
        "        candidate_ids = list(negative_candidates)\n",
        "        candidate_embeddings = np.array([document_embeddings[cid] for cid in candidate_ids])\n",
        "\n",
        "        # 向量化计算相似度\n",
        "        similarities = np.dot(candidate_embeddings, anchor_embedding) / (\n",
        "            np.linalg.norm(candidate_embeddings, axis=1) * np.linalg.norm(anchor_embedding)\n",
        "        )\n",
        "\n",
        "        max_index = np.argmax(similarities)\n",
        "        return self.document_id_to_text[candidate_ids[max_index]]\n",
        "\n",
        "    # def evaluate_validation_loss(self):\n",
        "    #     \"\"\"\n",
        "    #     A method to evaluate the model on validation data and calculate loss.\n",
        "    #     \"\"\"\n",
        "    #     self.model.eval()\n",
        "    #     validation_examples = self.prepare_validation_examples()  # Prepare validation examples\n",
        "\n",
        "    #     # Create DataLoader from validation examples\n",
        "    #     val_dataloader = DataLoader(validation_examples, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    #     total_loss = 0\n",
        "    #     total_samples = 0\n",
        "\n",
        "    #     # Evaluate over the entire validation set\n",
        "    #     for batch in val_dataloader:\n",
        "    #         # Pass the batch to the model and compute the loss\n",
        "    #         loss = self.model(batch)  # The model automatically computes the loss\n",
        "\n",
        "    #         total_loss += loss.item() * len(batch)  # Accumulate total loss (scaled by batch size)\n",
        "    #         total_samples += len(batch)  # Track the number of samples\n",
        "\n",
        "    #     avg_loss = total_loss / total_samples  # Average loss over all samples in the validation set\n",
        "    #     return avg_loss\n",
        "\n",
        "    # def prepare_validation_examples(self) -> list[InputExample]:\n",
        "    #     \"\"\"\n",
        "    #     Prepares validation examples from the validation data.\n",
        "    #     Adds hard negatives if specified.\n",
        "    #     \"\"\"\n",
        "    #     validation_examples = []\n",
        "\n",
        "    #     # Compute sentence embeddings for all documents at once to avoid recomputation\n",
        "    #     document_embeddings = {doc_id: self.model.encode(text) for doc_id, text in self.document_id_to_text.items()}\n",
        "\n",
        "    #     for qid, doc_ids in self.validate_query_id_to_relevant_doc_ids.items():\n",
        "    #         anchor = self.query_id_to_text[qid]\n",
        "    #         anchor_embedding = self.model.encode(anchor)  # Encode the query once\n",
        "\n",
        "    #         # Get all negative candidates for the current query\n",
        "    #         negative_candidates = list(set(self.document_ids) - set(doc_ids))\n",
        "\n",
        "    #         for doc_id in doc_ids:\n",
        "    #             positive = self.document_id_to_text[doc_id]\n",
        "    #             positive_embedding = document_embeddings[doc_id]  # Precomputed embedding of positive sample\n",
        "\n",
        "    #             if self.add_negative:\n",
        "    #                 # Hard negative mining: select a negative document that is similar but not relevant\n",
        "    #                 hard_negative = self.select_hard_negative(anchor_embedding, negative_candidates, document_embeddings)\n",
        "    #                 validation_examples.append(InputExample(texts=[anchor, positive, hard_negative]))\n",
        "    #             else:\n",
        "    #                 validation_examples.append(InputExample(texts=[anchor, positive]))\n",
        "\n",
        "    #     return validation_examples"
      ],
      "metadata": {
        "id": "vKJhmhUN2nWi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "id": "TyVetTcROuoA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "033c07fb8938402783544d9d4a20df0f",
            "5950c7ea644d43c4be49ccb72085ec0a",
            "2ffd13b3eb7941b2a40b1f0ecf9154d4",
            "94c61c667c6d420287d52ba6f7b7112b",
            "de384225289a42ccaf980df837e39e79",
            "096bd6dbc4ae4881aa4af18377b5a0c1",
            "5ce54348375d41649979775bfca9bd9b",
            "5adcd9dcf276497e9f7e3a389501d856",
            "7f1559e240594281bff6ca593ce1ce50",
            "7e77c783a7f449ef8939b1f322ddb806",
            "24e19d0f245040d5a17ebfaba4dd84b9",
            "250e94438ca44e7496ef7d6d944210de",
            "a43b4513756f44f59a1841c420028f51",
            "2fb067a18b754ac2ae7451be3383db43",
            "224ba26a5d3f45b4847a7d45f95ec827",
            "6d568c162ad741f69d473d573ac63f63",
            "c19117dce81d4e738ef8d72f1b98465e",
            "39948f9741fe42b7b044a31d2952c441",
            "4a6e8904c40a4400ad0034c31a2a5a23",
            "59d5a57abea24ee697e5c86d80bd3364"
          ]
        },
        "outputId": "8b64898e-c3d0-4c91-9485-1b3f583741e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "033c07fb8938402783544d9d4a20df0f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and use the model\n",
        "model = TextSimilarityModel(\"BeIR/nfcorpus\", \"BeIR/nfcorpus-qrels\")"
      ],
      "metadata": {
        "id": "Q17_1D0wB-cp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the outputs\n",
        "print(\"Ranking with sentence_transformer...\")\n",
        "model.rank_documents(encoding_method='sentence_transformer')\n",
        "map_score = model.mean_average_precision()\n",
        "print(\"Mean Average Precision:\", map_score)\n",
        "\n",
        "# # Download glove txt\n",
        "# glove_file_path = 'glove.6B.50d.txt'\n",
        "# embeddings_id = \"1sX7UOmk8dGQfGhe8s1qOyN10XvL-8qHx\"\n",
        "\n",
        "# if not os.path.exists(glove_file_path):\n",
        "#     print(\"Donwloading embedings...\\n\\n\")\n",
        "#     gdown.download(id=embeddings_id, output=glove_file_path, quiet=False)\n",
        "\n",
        "# # Compare the outputs\n",
        "# print(\"Ranking with glove...\")\n",
        "# model.rank_documents(encoding_method='glove')\n",
        "# map_score = model.mean_average_precision()\n",
        "# print(\"Mean Average Precision:\", map_score)\n",
        "\n",
        "model.show_ranking_documents(\"Breast Cancer Cells Feed on Cholesterol\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "k0oY1d-dv85x",
        "outputId": "9d9870b1-3ad9-4066-c5c6-9af76ec8a061"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking with sentence_transformer...\n",
            "Mean Average Precision: 0.4635071548112422\n",
            "Top 10 documents for query: Breast Cancer Cells Feed on Cholesterol\n",
            "\n",
            "1. Score: 0.6208, Document: The specific role of dietary fat in breast cancer progression is unclear, although a low-fat diet was associated with decreased recurrence of estrogen receptor alpha negative (ER(-)) breast cancer. ER(-) basal-like MDA-MB-231 and MDA-MB-436 breast cancer cell lines contained a greater number of cytoplasmic lipid droplets compared to luminal ER(+) MCF-7 cells. Therefore, we studied lipid storage functions in these cells. Both triacylglycerol and cholesteryl ester (CE) concentrations were higher in the ER(-) cells, but the ability to synthesize CE distinguished the two types of breast cancer cells. Higher baseline, oleic acid- and LDL-stimulated CE concentrations were found in ER(-) compared to ER(+) cells. The differences corresponded to greater mRNA and protein levels of acyl-CoA:cholesterol acyltransferase 1 (ACAT1), higher ACAT activity, higher caveolin-1 protein levels, greater LDL uptake, and lower de novo cholesterol synthesis in ER(-) cells. Human LDL stimulated proliferation of ER(-) MDA-MB-231 cells, but had little effect on proliferation of ER(+) MCF-7 cells. The functional significance of these findings was demonstrated by the observation that the ACAT inhibitor CP-113,818 reduced proliferation of breast cancer cells, and specifically reduced LDL-induced proliferation of ER(-) cells. Taken together, our studies show that a greater ability to take up, store and utilize exogenous cholesterol confers a proliferative advantage to basal-like ER(-) breast cancer cells. Differences in lipid uptake and storage capability may at least partially explain the differential effect of a low-fat diet on human breast cancer recurrence.\n",
            "2. Score: 0.6041, Document: The content of low density lipoprotein (LDL) receptors in tissue from primary breast cancers was determined and its prognostic information compared with that of variables of established prognostic importance. Frozen tumour specimens were selected, and tissue from 72 patients (32 of whom had died) were studied. The LDL receptor content showed an inverse correlation with the survival time. Analysis by a multivariate statistical method showed that the presence of axillary metastasis, content of receptors for oestrogen and LDL, diameter of the tumour, and DNA pattern were all of prognostic value with regard to patient survival. Improved methods of predicting survival time in patients with breast cancer may be of value in the choice of treatment for individual patients.\n",
            "3. Score: 0.5977, Document: BACKGROUND: Preclinical studies have shown that statins, particularly simvastatin, can prevent growth in breast cancer cell lines and animal models. We investigated whether statins used after breast cancer diagnosis reduced the risk of breast cancer-specific, or all-cause, mortality in a large cohort of breast cancer patients. METHODS: A cohort of 17,880 breast cancer patients, newly diagnosed between 1998 and 2009, was identified from English cancer registries (from the National Cancer Data Repository). This cohort was linked to the UK Clinical Practice Research Datalink, providing prescription records, and to the Office of National Statistics mortality data (up to 2013), identifying 3694 deaths, including 1469 deaths attributable to breast cancer. Unadjusted and adjusted hazard ratios (HRs) for breast cancer-specific, and all-cause, mortality in statin users after breast cancer diagnosis were calculated using time-dependent Cox regression models. Sensitivity analyses were conducted using multiple imputation methods, propensity score methods and a case-control approach. RESULTS: There was some evidence that statin use after a diagnosis of breast cancer had reduced mortality due to breast cancer and all causes (fully adjusted HR = 0.84 [95% confidence interval = 0.68-1.04] and 0.84 [0.72-0.97], respectively). These associations were more marked for simvastatin 0.79 (0.63-1.00) and 0.81 (0.70-0.95), respectively. CONCLUSIONS: In this large population-based breast cancer cohort, there was some evidence of reduced mortality in statin users after breast cancer diagnosis. However, these associations were weak in magnitude and were attenuated in some sensitivity analyses.\n",
            "4. Score: 0.5772, Document: Purpose To further clarify the relationship between total cholesterol and cancer, which remains unclear. Methods We prospectively examined the association between total cholesterol and site-specific and all-cancer incidence among 1,189,719 Korean adults enrolled in the National Health Insurance Corporation who underwent a standardized biennial medical examination in 1992 to 1995 and were observed for 14 years until cancer diagnosis or death. Results Over follow-up, 53,944 men and 24,475 women were diagnosed with a primary cancer. Compared with levels less than 160 mg/dL, high total cholesterol (≥ 240 mg/dL) was positively associated with prostate cancer (hazard ratio [HR], 1.24; 95% CI, 1.07 to 1.44; P trend = .001) and colon cancer (HR, 1.12; 95% CI, 1.00 to 1.25; P trend = .05) in men and breast cancer in women (HR, 1.17; 95% CI, 1.03 to 1.33; P trend = .03). Higher total cholesterol was associated with a lower incidence of liver cancer (men: HR, 0.42; 95% CI, 0.38 to 0.45; P trend < .001; women: HR, 0.32; 95% CI, 0.27 to 0.39; P trend < .001), stomach cancer (men: HR, 0.87; 95% CI, 0.82 to 0.93; P trend ≤ .001; women: HR, 0.86; 95% CI, 0.77 to 0.97; P trend = .06), and, in men, lung cancer (HR, 0.89; 95% CI, 0.82 to 0.96; P trend < .001). Results for liver cancer were slightly attenuated after additional adjustment for liver enzyme levels and hepatitis B surface antigen status (men: HR, 0.60; P trend < .001; women: HR, 0.46; P trend = .003) and exclusion of the first 10 years of follow-up (men: HR, 0.59; P trend < .001; women: HR, 0.44; P trend < .001). Total cholesterol was inversely associated with all-cancer incidence in both men (HR, 0.84; 95% CI, 0.81 to 0.86; P trend < .001) and women (HR, 0.91; 95% CI, 0.87 to 0.95; P trend < .001), but these associations were attenuated after excluding incident liver cancers (men: HR, 0.95; P trend < .001; women: HR, 0.98; P trend = .32). Conclusion In this large prospective study, we found that total cholesterol was associated with the risk of several different cancers, although these relationships differed markedly by cancer site.\n",
            "5. Score: 0.5572, Document: Breast cancer is the leading cause of cancer-related deaths in women in the United States and many other countries. There is an immediate need for more effective and less toxic therapeutic and preventive strategies for many cancers, especially for breast cancer. Natural products are being tested with a hope of identifying novel potent molecules as anticancer agents. Phytochemicals and dietary compounds have been used for the treatment of various illnesses throughout history due to their safety, low toxicity, and general availability. Currently, many active phytochemicals are in clinical trials. Preclinical and clinical studies have indicated that daily consumption of dietary phytochemicals reduces the risk of several cancers. Phytochemicals can inhibit, delay, or reverse carcinogenesis by inducing detoxifying and antioxidant enzymes, by regulating inflammatory/proliferative signaling pathways, and by inducing apoptosis. This review article describes some of the potential natural cancer preventive compounds, along with a mechanistic discussion of their interactions with key cellular signal transduction pathways as well as their contribution to the suppression of breast cancer cell growth.\n",
            "6. Score: 0.5490, Document: Diet plays a seminal role in the prevention and treatment of cardiovascular disease. Consumption of tree nuts has been shown to reduce low-density lipoprotein cholesterol (LDL-C), a primary target for coronary disease prevention, by 3-19%. Almonds have been found to have a consistent LDL-C-lowering effect in healthy individuals, and in individuals with high cholesterol and diabetes, in both controlled and free-living settings. Almonds are low in saturated fatty acids, rich in unsaturated fatty acids, and contain fiber, phytosterols, and plant protein. Other cardioprotective nutrients unique to almonds include α-tocopherol, arginine, magnesium, copper, manganese, calcium, and potassium. Mechanisms responsible for the LDL-C reduction observed with almond consumption are likely associated with the nutrients almonds provide. Biologically active by nature, these nutrients target primary mechanistic routes of LDL-C reduction, including decreased (re)absorption of cholesterol and bile acid, increased bile acid and cholesterol excretion, and increased LDL-C receptor activity. The nutrients present in almonds may regulate enzymes involved in de novo cholesterol synthesis and bile acid production. Research is needed to understand all mechanisms by which almonds reduce cardiovascular disease risk. © 2011 International Life Sciences Institute.\n",
            "7. Score: 0.5462, Document: BACKGROUND: Breast cancer is the most commonly diagnosed cancer among women in the United States. Extensive research has been completed to evaluate the relationship between dietary factors and breast cancer risk and survival after breast cancer; however, a summary report with clinical inference is needed. Materials and METHODS: This review summarizes the current epidemiological and clinical trial evidence relating diet to breast cancer incidence, recurrence, survival, and mortality. The review includes emerging epidemiological studies that assess risk within breast cancer subtypes as well as a summary of previous and ongoing dietary intervention trials designed to modify breast cancer risk. RESULTS: The available literature suggests that both low-fat and high-fiber diets may be weakly protective against breast cancer, whereas total energy intake and alcohol appear to be positively associated. Fiber may be weakly protective possibly through modulation of estrogen, whereas fruit and vegetable intake is not clearly associated with risk. Obesity is a risk factor for postmenopausal disease, and adult weight gain should be avoided to reduce risk. In survivors, diet has the greatest potential influence on overall mortality rather than breast cancer-specific events. CONCLUSION: Diet is modestly associated with breast cancer risk; associations appear more pronounced for postmenopausal disease, and healthy choices after diagnosis and treatment likely support longevity more so than reduced risk for recurrent disease.\n",
            "8. Score: 0.5399, Document: Recent studies have suggested that statins, an established drug group in the prevention of cardiovascular mortality, could delay or prevent breast cancer recurrence but the effect on disease-specific mortality remains unclear. We evaluated risk of breast cancer death among statin users in a population-based cohort of breast cancer patients. The study cohort included all newly diagnosed breast cancer patients in Finland during 1995–2003 (31,236 cases), identified from the Finnish Cancer Registry. Information on statin use before and after the diagnosis was obtained from a national prescription database. We used the Cox proportional hazards regression method to estimate mortality among statin users with statin use as time-dependent variable. A total of 4,151 participants had used statins. During the median follow-up of 3.25 years after the diagnosis (range 0.08–9.0 years) 6,011 participants died, of which 3,619 (60.2%) was due to breast cancer. After adjustment for age, tumor characteristics, and treatment selection, both post-diagnostic and pre-diagnostic statin use were associated with lowered risk of breast cancer death (HR 0.46, 95% CI 0.38–0.55 and HR 0.54, 95% CI 0.44–0.67, respectively). The risk decrease by post-diagnostic statin use was likely affected by healthy adherer bias; that is, the greater likelihood of dying cancer patients to discontinue statin use as the association was not clearly dose-dependent and observed already at low-dose/short-term use. The dose- and time-dependence of the survival benefit among pre-diagnostic statin users suggests a possible causal effect that should be evaluated further in a clinical trial testing statins’ effect on survival in breast cancer patients.\n",
            "9. Score: 0.5343, Document: We previously demonstrated that high serum enterolactone levels are associated with a reduced incidence of breast cancer in healthy women. The present study was aimed at investigating whether a similar association might be found between serum enterolactone levels and the mortality of women with early breast cancer. The levels of enterolactone in cryopreserved serum aliquots obtained from 300 patients, operated on for breast cancer, were measured using a time-resolved fluoro-immunoassay. Levels were analyzed in respect to the risk of mortality following surgery. Cox proportional hazard regression models were used to check for prognostic features, to estimate hazard ratios for group comparisons and to test for the interaction on mortality hazards between the variables and enterolactone concentrations. The Fine and Gray competing risk proportional hazard regression model was used to predict the probabilities of breast cancer-related and breast cancer-unrelated mortalities. At a median follow-up time of 23 years (range 0.6-26.1), 180 patients died, 112 of whom died due to breast cancer-related events. An association between a decreased mortality risk and enterolactone levels ≥ 10 nmol/l was found in respect to both all-cause and breast cancer-specific mortality. The difference in mortality hazards was statistically significant, but it appeared to decrease and to lose significance after the first 10 years, though competing risk analysis showed that breast cancer-related mortality risk remained constantly lower in those patients with higher enterolactone levels. Our findings are consistent with those of most recent literature and provide further evidence that mammalian lignans might play an important role in reducing all-cause and cancer-specific mortality of the patients operated on for breast cancer.\n",
            "10. Score: 0.5332, Document: While many factors are involved in the etiology of cancer, it has been clearly established that diet significantly impacts one’s risk for this disease. More recently, specific food components have been identified which are uniquely beneficial in mitigating the risk of specific cancer subtypes. Plant sterols are well known for their effects on blood cholesterol levels, however research into their potential role in mitigating cancer risk remains in its infancy. As outlined in this review, the cholesterol modulating actions of plant sterols may overlap with their anti-cancer actions. Breast cancer is the most common malignancy affecting women and there remains a need for effective adjuvant therapies for this disease, for which plant sterols may play a distinctive role.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune all-MiniLM-L6-v2 sentence transformer model\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "model.fine_tune_model(batch_size=32, num_epochs=5, save_model_path=\"finetuned_senBERT_train_v2\", lr=5e-5)  # Adjust batch size and epochs as needed\n",
        "\n",
        "model.rank_documents()\n",
        "map_score = model.mean_average_precision()\n",
        "print(\"Mean Average Precision:\", map_score)"
      ],
      "metadata": {
        "id": "SzXbmRmCO1Ay",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193,
          "referenced_widgets": [
            "a727df377e7e4f55b4a4121865892905",
            "b9524ee9d94644d4be887309bde9e5ec",
            "c768502d2ff843a58475735eae03f88e",
            "6d9a6a5938b04f2d868e627db4db1b13",
            "34eefb71cfa14222893a831216fe136e",
            "fe8af785c8b441edb2411bc7f17743fa",
            "a34c1b56af824462ab2d038d0fe6d908",
            "16de35103feb4d8086fdb3e9abf84090",
            "f8a4efee77174f78821a044d83c7b7c6",
            "6c34a2552fa14a58acb2ca3f8eb3c2c4",
            "1d6187fdb5ec47f09108c1bf1a9e9531"
          ]
        },
        "outputId": "fa9f6098-5744-4172-c0f8-843d978b881d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a727df377e7e4f55b4a4121865892905"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17280' max='17280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17280/17280 12:57, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.303200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.305300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.289700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.289900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.291000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.289100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.282200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.268900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.286300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.273100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.270700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>1.272800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.288300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>1.248700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.279200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>1.275000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.257300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>1.262600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>1.272200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>1.253200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>1.262100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.250900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>1.263900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>1.267700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>1.280800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.257800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>1.226200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>1.249900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>1.232600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>1.252500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>1.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>1.244200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Precision: 0.4538383725810011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.kaggle_rank_documents()"
      ],
      "metadata": {
        "id": "JW9BfmmW1You"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RKXv_hz1Zfs6",
        "outputId": "cb6c6843-025f-4fc3-bed6-7f9157dab085"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "033c07fb8938402783544d9d4a20df0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_5ce54348375d41649979775bfca9bd9b"
          }
        },
        "5950c7ea644d43c4be49ccb72085ec0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5adcd9dcf276497e9f7e3a389501d856",
            "placeholder": "​",
            "style": "IPY_MODEL_7f1559e240594281bff6ca593ce1ce50",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "2ffd13b3eb7941b2a40b1f0ecf9154d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7e77c783a7f449ef8939b1f322ddb806",
            "placeholder": "​",
            "style": "IPY_MODEL_24e19d0f245040d5a17ebfaba4dd84b9",
            "value": ""
          }
        },
        "94c61c667c6d420287d52ba6f7b7112b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_250e94438ca44e7496ef7d6d944210de",
            "style": "IPY_MODEL_a43b4513756f44f59a1841c420028f51",
            "value": true
          }
        },
        "de384225289a42ccaf980df837e39e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2fb067a18b754ac2ae7451be3383db43",
            "style": "IPY_MODEL_224ba26a5d3f45b4847a7d45f95ec827",
            "tooltip": ""
          }
        },
        "096bd6dbc4ae4881aa4af18377b5a0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d568c162ad741f69d473d573ac63f63",
            "placeholder": "​",
            "style": "IPY_MODEL_c19117dce81d4e738ef8d72f1b98465e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "5ce54348375d41649979775bfca9bd9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "5adcd9dcf276497e9f7e3a389501d856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1559e240594281bff6ca593ce1ce50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e77c783a7f449ef8939b1f322ddb806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e19d0f245040d5a17ebfaba4dd84b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "250e94438ca44e7496ef7d6d944210de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43b4513756f44f59a1841c420028f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fb067a18b754ac2ae7451be3383db43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224ba26a5d3f45b4847a7d45f95ec827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6d568c162ad741f69d473d573ac63f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19117dce81d4e738ef8d72f1b98465e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39948f9741fe42b7b044a31d2952c441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a6e8904c40a4400ad0034c31a2a5a23",
            "placeholder": "​",
            "style": "IPY_MODEL_59d5a57abea24ee697e5c86d80bd3364",
            "value": "Connecting..."
          }
        },
        "4a6e8904c40a4400ad0034c31a2a5a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d5a57abea24ee697e5c86d80bd3364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a727df377e7e4f55b4a4121865892905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9524ee9d94644d4be887309bde9e5ec",
              "IPY_MODEL_c768502d2ff843a58475735eae03f88e",
              "IPY_MODEL_6d9a6a5938b04f2d868e627db4db1b13"
            ],
            "layout": "IPY_MODEL_34eefb71cfa14222893a831216fe136e"
          }
        },
        "b9524ee9d94644d4be887309bde9e5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8af785c8b441edb2411bc7f17743fa",
            "placeholder": "​",
            "style": "IPY_MODEL_a34c1b56af824462ab2d038d0fe6d908",
            "value": "Computing widget examples:   0%"
          }
        },
        "c768502d2ff843a58475735eae03f88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16de35103feb4d8086fdb3e9abf84090",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8a4efee77174f78821a044d83c7b7c6",
            "value": 1
          }
        },
        "6d9a6a5938b04f2d868e627db4db1b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c34a2552fa14a58acb2ca3f8eb3c2c4",
            "placeholder": "​",
            "style": "IPY_MODEL_1d6187fdb5ec47f09108c1bf1a9e9531",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "34eefb71cfa14222893a831216fe136e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fe8af785c8b441edb2411bc7f17743fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34c1b56af824462ab2d038d0fe6d908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16de35103feb4d8086fdb3e9abf84090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8a4efee77174f78821a044d83c7b7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c34a2552fa14a58acb2ca3f8eb3c2c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d6187fdb5ec47f09108c1bf1a9e9531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}